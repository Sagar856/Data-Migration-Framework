{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ab803738-f250-4dbd-9fa6-a40403601508",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "94f26f51-45d9-4797-8200-3b5fae5bad88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Parameters extraction\n",
    "Parameters = dbutils.widgets.get(\"Parameters\")\n",
    "Parameters = json.loads(Parameters)\n",
    "\n",
    "ProcessInstanceId = 0\n",
    "ProcessQueueId = 0\n",
    "StageId = 0\n",
    "TableName = \"\"\n",
    "\n",
    "for p in Parameters:\n",
    "    if p.get(\"TableName\") == \"Products\":\n",
    "        ProcessInstanceId = int(p.get(\"ProcessInstanceId\"))\n",
    "        ProcessQueueId = int(p.get(\"ProcessQueueId\"))\n",
    "        StageId = int(p.get(\"StageId\"))\n",
    "        TableName = str(p.get(\"TableName\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "96c80061-6a45-4889-8eef-6bd455018982",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Mark current table as InProgress\n",
    "if StageId == 3:\n",
    "    spark.sql(f\"\"\"\n",
    "        update control.processqueue\n",
    "        set ProcessStatus = 'InProgress',\n",
    "            ProcessStartTime = current_timestamp()\n",
    "        where StageId = {StageId}\n",
    "            and ProcessInstanceId = {ProcessInstanceId}\n",
    "            and ProcessQueueId = {ProcessQueueId}\n",
    "            and TableName = '{TableName}';\n",
    "    \"\"\")\n",
    "else:\n",
    "    raise Exception(f\"Stage Id is not relavent to R2B-transformation for table: {TableName}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "56bb3851-fcb8-4c1e-b34c-e0e7920139d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Write tables to Silver\n",
    "status = False\n",
    "\n",
    "try:\n",
    "    # Read source (bronze) table\n",
    "    src_df = spark.table(\"workspace.bronze.products\")\n",
    "\n",
    "    # Select and add computed columns\n",
    "    final_df = (\n",
    "        src_df.select(\n",
    "            \"ProductId\",\n",
    "            \"ProductName\",\n",
    "            \"ProductCategory\",\n",
    "            \"ProductPrice\",\n",
    "            F.current_timestamp().alias(\"LoadTimestamp\"),\n",
    "            F.lit(\"Source_CSV\").alias(\"SourceSystem\"),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Overwrite/create the Delta table at the target\n",
    "    (final_df.write\n",
    "        .format(\"delta\")\n",
    "        .mode(\"overwrite\")            # mirrors CREATE OR REPLACE TABLE ... AS SELECT\n",
    "        .option(\"overwriteSchema\", \"true\")\n",
    "        .saveAsTable(\"workspace.silver.products\"))\n",
    "    status = True\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    status = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "21d166b8-c6b0-43ae-9dca-c1eac4413f92",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Mark file as Success/Failed\n",
    "\n",
    "if status == True:\n",
    "    spark.sql(f\"\"\"\n",
    "        UPDATE control.processqueue\n",
    "        SET\n",
    "            ProcessStatus = 'Succeeded',\n",
    "            ProcessEndTime = current_timestamp(),\n",
    "            ProcessDuration = CAST(\n",
    "                (unix_timestamp(current_timestamp()) - unix_timestamp(ProcessStartTime)) / 60\n",
    "                AS BIGINT\n",
    "            )\n",
    "        WHERE\n",
    "            StageId = {StageId}\n",
    "            AND ProcessInstanceId = {ProcessInstanceId}\n",
    "            AND ProcessQueueId = {ProcessQueueId}\n",
    "            AND TableName = '{TableName}'\n",
    "            \"\"\")\n",
    "    print(f\"{TableName} Marked as Successful\")\n",
    "elif status == False:\n",
    "        spark.sql(f\"\"\"\n",
    "        UPDATE control.processqueue\n",
    "        SET\n",
    "            ProcessStatus = 'Failed',\n",
    "            ProcessEndTime = current_timestamp(),\n",
    "            ProcessDuration = CAST(\n",
    "                (unix_timestamp(current_timestamp()) - unix_timestamp(ProcessStartTime)) / 60\n",
    "                AS BIGINT\n",
    "            )\n",
    "        WHERE\n",
    "            StageId = {StageId}\n",
    "            AND ProcessInstanceId = {ProcessInstanceId}\n",
    "            AND ProcessQueueId = {ProcessQueueId}\n",
    "            AND TableName = '{TableName}'\n",
    "            \"\"\")\n",
    "        print(f\"{TableName} Marked as Failed\")\n",
    "        raise Exception(f\"Hard failure: {TableName} Failure detected\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "B2S_Products",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
